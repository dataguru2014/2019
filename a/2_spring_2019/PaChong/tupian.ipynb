{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file D:\\anaconda\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "for i in range(1,2):\n",
    "    F=open(r'D:\\ppt图片源码%s.txt'%i).read()\n",
    "    soup=BeautifulSoup(F)\n",
    "    tar=soup.body.find('dl', class_=\"dlbox\").find('ul', class_=\"tplist\")\n",
    "    for i in tar.findAll('li'):\n",
    "        url=i.img.get('src')\n",
    "        name=i.img.get('alt')\n",
    "        path=r'E:\\tupian\\%s.jpg'%name\n",
    "#         urlinfo=requests.get(url)      \n",
    "#         f=open(path,'wb')\n",
    "#         f.write(urlinfo.content)\n",
    "#         f.close()\n",
    "        save_poto(path,url)\n",
    "    \n",
    "def save_poto(path,url):\n",
    "    urlinfo=requests.get(url)\n",
    "    f=open(path,'wb')\n",
    "    f.write(urlinfo.content)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "f=open('D:\\ppt图片源码1.txt','r',encoding='gbk').read()\n",
    "p=re.findall('<dl class=\"dlbox\">(.*?)<table width=',f,re.S)[0]\n",
    "urllist=re.findall('img src=\"(.*?)\" alt',p,re.S)\n",
    "namelist=re.findall(' alt=\"(.*?)\"/></a>',p)\n",
    "# print(url)\n",
    "\n",
    "def save_photo(url,path):\n",
    "    urlinfo=requests.get(url)\n",
    "    ff=open(path,'wb')\n",
    "    ff.write(urlinfo.content)\n",
    "    ff.close()\n",
    "    \n",
    "for url,j in zip(urllist,namelist):\n",
    "    path=r'E:\\tupian\\tupian\\%s.jpg'%j\n",
    "    save_photo(url,path)\n",
    "    \n",
    "#     urlinfo=requests.get(i)\n",
    "#     poto=urlinfo.content\n",
    "#     ff=open(path,'wb')\n",
    "#     ff.write(poto)\n",
    "#     ff.close\n",
    "\n",
    "\n",
    "# def get_imag(path,url,name):\n",
    "#     h=requests.get(url)\n",
    "#     n='{0}.jpg'.format(name)\n",
    "#     lujing=os.path.join(path,n)     #path.join的用法\n",
    "#     f=open(lujing,'wb')\n",
    "#     f.write(h.content)\n",
    "#     f.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
