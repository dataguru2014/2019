Hi everyone. We are starting course about machine learning competitions. In this course, you will learn a lot of tricks and best practices about data science competitions. Before we start to learn advanced techniques, we need to understand the basics. In this video, I will explain the main concept of competitions and you will become familiar with competition mechanics. A variety of machinery competition is very high. In some, participants are asked to process texts. In others, to classify picture or select the best advertising. Despite the variety, all of these competitions are very similar in structure. Usually, they consist of the same elements or concepts which we will discuss in this video. Let's start with a data. Data is what the organizers give us as training material. We will use it in order to produce our solution. Data can be represented in a variety of formats. SSV file with several columns , a text file, an archive with pictures, a database dump, a disabled code or even all together. With the data, usually there is a description. It's useful to read it in order to understand what we'll work with and which feature can be extracted. Here is an example from Kaggle. From the top, we see several files with data, and below, is their description. Sometimes in addition to data issued by organizers, we can use other data. For example, in order to improve image classification model, one may use a publicly available data set of images. But this depends on a particular competition and you need to check the rules. The next concept is a model. This is exactly what we will build during the competition. It's better to think about model not as one specific algorithm, but something that transforms data into answers. The model should have two main properties. It should produce best possible prediction and be reproducible. In fact, it can be very complicated and contain a lot of algorithms, handcrafted features, use a variety of libraries as this model of the winners of the Homesite competition shown on this slide. It's large and includes many components. But in the course, we will learn how to build such models. To compare our model with the model of other participants, we will send our predictions to the server or in other words, make the submission. Usually, you're asked about predictions only. Sources or models are not required. And also there are some exceptions, cool competitions, where participants submit their code. In this course, we'll focus on traditional challenges where a competitor submit only prediction outputs. Often, I can not just provide a so-called sample submission. An example of how the submission file should look like, look at the sample submission from the Zillow competition. In it is the first column. We must specify the ID of the object and then specify our prediction for it. This is typical format that is used in many competitions. Now, we move to the next concept, evaluation function. When you submit predictions, you need to know how good is your model. The quality of the model is defined by evaluation function. In essence and simply the function, the text prediction and correct answers and returns a score characterizes the performance of the solution. The simplest example of such a function is the accurate score. This is just a rate of correct answers. In general, there are a lot of such functions. In our course, we will carefully consider some of them. The description of the competition always indicates which evaluation function is used. I strongly suggest you to pay attention to this function because it is what we will try to optimize. But often, we are not interested in the score itself. We should only care about our relative performance in comparison to other competitors. So we move to the last point we are considering, the leaderboard. The leaderboard is the rate which provides you with information about performance of all participating teams. Most machine learning competition platforms keep your submission history, but the leaderboard usually shows only your best score and position. They cannot as that submission score, reveal some information about data set. And, in extreme cases, one can obtain ground truth targets after sending a lot of submissions. In order to handle this, the set is divided into two parts, public and private. This split is hidden from users and during the competition, we see the score calculated only on public subset of the data. The second part of data set is used for private leaderboard which is revealed after the end of the competition. Only this second part is used for final rating. Therefore, a standard competition routine looks like that. You as the competition, you analyze the data, improve model, prepare submission, send it, see leaderboard score. You repeat this action several times. All this time, only public leaderboard is available. By the end of the competition, you should select submissions which will be used for final scoring. Usually, you are allowed to select two final submissions. Choose wisely. Sometimes public leaderboard scores might be misleading. After the competition deadline, public leaderboard is revealed, and its used for the final rating and defining the winners. That was a brief overview of competition mechanics. Keep in mind that many concepts can be slightly different in a particular competition. All details, for example, where they can join into teams or use external data, you will find in the rules. Strongly suggest you to read the rules carefully before joining the competition. Now, I want to say a few words about competition platforms. Although Kaggle is the biggest and most famous one, there is a number of smaller platforms or even single-competition sites like KDD and VizDooM. Although this list will change over time, I believe you will find the competition which is most relevant and interesting for you. Finally, I want to tell you about the reasons to participate in data science competition. The main reason is that competition is a great opportunity for learning. You communicate with other participants, try new approaches and get a lot of experience. Second reason is that competition often offer you non-trivial problems and state-of-the-art approaches. It allows you to broaden the horizons and look at some everyday task from a different point of view. It's also a great way to become recognizable, get some kind of frame inside data science community and receive a nice job offer. The last reason to participate is that you have a chance for winning some money. It shouldn't be the main goal, just a pleasant bonus. In this video, we analyzed the basic concept of the competition, talked about platforms and reasons for participation. In the next video, we will talk about the difference between real life and competitions.[MUSIC] Hi, everyone. In this video we'll learn
how to use Kaggle for participation in data
science competitions. Let's open kaggle.com. On the Competitions page, we can see
a list of currently running competitions. Every competition has a page which
consists of title, short description, price budget, number of participating
teams, and time before the end. Information involves all
previously running competitions, we can find if we click to All. Let's select some challenge and
see how it organized. Here, we see several tabs which we'll
explore, and let's start with Overview. In the Description section we see
an introduction provided by organizers. In the Description, there is a short
story about company and tasks, sometimes with illustration. At the Evaluation page, we see
the description of the target metric. In this challenge, target metric
is the Mean Absolute Error between the logarithmic transform predictions and
ground truth values. This page also contains example of sample
submission file, which is typical for such kind of competitions. Now let's move to the Prize page. In the Prize,
page we can find information about prizes. Take notice that in the title we have
information about the whole money budget, and this page,
we see how it will be split among winners. I want to highlight that
in order to get money, you need not only be in top three teams,
but also beat a Zillow benchmark model. Now let's see, Timeline page, which
contains all the information about dates. For example,
when competition starts, ends, when will the Team Merger deadline and
then what month. All the details about competition,
we can find in the Rules. So we need to check really the rules. Here we can find that team
limit is three individual, that we have maximum of five
submissions per day, that you, for example, should be at least
18 years old to participate. And that, find it, that external data are not allowed. I strongly suggest you to read the rules
carefully before joining the competition. And after reading, you should accept it,
but I already accepted it. Now, let's check this, Data. Here we have data provided by
the organizers, several files which we can download, and sample submission among
them, and the description of the data. Here we have description of files,
description of data fields, and more importantly a description
of train and test split. This is quite useful information in
order to set up right validation scheme. If you have any question about data or
other questions to ask, or insights to share, you can go to the forum,
which we can find under Discussion tab. Usually it contain a lot of topics or
threads, like Welcome, questions about validations, questions about train and
test data, and so on and so on. Every topic have title,
number of comments, and number of reports. Let's see some of them. Here we have main message,
a lot of comments, in this particular we
have only one comments. Each we can up vote or down vote and
reply to by click the reply button. That was a brief overview on forum and
now we switch to the Kernels. Usually, I run my code locally,
but sometimes it would be handy to check an idea quickly or share code
with other participants or teammates. This is what Kernels are for. You can think of Kernel as a small virtual
machine in which you write your code, execute it, and share it. Let's take a look at some Kernel,
for example for this one. This show explanatory data analysis
on the Zillow competition. It took quite long, contain a lot of
pictures, and I believe it very useful. Here we can see comments for
this, different versions. And in order,
if you want to make a copy and edit it, we need to Fork this Notebook. It doesn't matter how your
predictions were produced, locally or by Kernel, you should submit
them through a specialized form. So go back to the competition. Go to submissions. I already submit sample submission,
you can do the same. Click submit predictions,
and drag and drop file here. Let's look at my submission. After submission,
you will see it on the leaderboard. This is my sample submission. Leaderboard contains information
about all the teams. So here we have team name or just name
in case of single competition team. Score which we produced,
number of submissions, time since the last submissions, and
position data over seven last days. For example, this means that this guy
drops 19 positions during the last week. That was a brief overview
of Kaggle interface. Further, I will tell some extra
information about the platform. So let's move to Overview
page at the bottom. And here,
we see information about points and tiers. As mentioned here, the competition will be
counting towards ranking points an tiers. If you participate,
it will be beneficial for your rating. Sometimes, especially in educational
competitions, it's not like that. Information about Kaggle Progression
System we can find if we click this link, where we can read information about
tiers like novice, contributor, master, grandmaster. About medals and ranking points. This ranking points, I use for
global User Ranking. Let's check it. So, we have user ranking page, and we see all the users ranked, and
with links to their profile. Let's check some profile,
for example mine. And here we have photo,
name, some information, geo information, information about
past competitions, medals, and so on. In addition, I want to say a few words
about ability to host competition. Kaggle has this ability. Click Host competition, and
there is special Kaggle in class. At in class, everyone can host
their own competition for free and invite people to participate. This option is quite often used in
various educational competitions. So this was a brief overview
of Kaggle platform. Thank for your attention. [MUSIC]In this video, I want to talk about complexity of real world machine learning pipelines and how they differ from data science competitions. Also, we will discuss the philosophy of the competitions. Real world machine learning problems are very complicated. They include several stages, each of them is very important and require attention. Let's imagine that we need to build an an anti-spam system and consider the basic steps that arise when building such a system. First of all, before doing any machine learning stuff, you need to understand the problem from a business point of view. What do you want to do? For what? How can it help your users? Next, you need to formalize the task. What is the definition of spam? What exactly is to be predicted? The next step is to collect data. You should ask yourself, what data can we use? How to mine examples of spam and non-spam? Next, you need to take care of how to clean your data and pre-process it. After that, you need to move on to building models. To do this, you need to answer the questions, which class of model is appropriate for this particular task? How to measure performance? How to select the best model? The next steps are to check the effectiveness on the model in real scenario, to make sure that it works as expected and there was no bias introduced by learning process. Does the model actually block spam? How often does it block non-spam emails? If everything is fine, then the next step is to deploy the model. Or in other words, make it available to users. However, the process doesn't end here. Your need to monitor the model performance and re-train it on new data. In addition, you need to periodically revise your understanding of the problem and go for the cycle again and again. In contrast, in competitions we have a much simpler situation. All things about formalization and evaluation are already done. All data collected and target metrics fixed. Therefore your mainly focus on pre-processing the data, picking models and selecting the best ones. But, sometimes you need to understand the business problem in order to get insights or generate a new feature. Also sometimes organizers allow the usage of external data. In such cases, data collection become a crucial part of the solution. I want to show you the difference between real life applications and competitions more thoroughly. This table shows that competitions are much simpler than real world machine learning problems. The hardest part, problem formalization and choice of target metric, is already done. Also questions related to deploying out of scope, so participants can focus just on modeling part. One may notice that in this table data collection and model complexity roles have no and yes in competition column. The reason for that, that in some competitions you need to take care of these things. But usually it's not the case. I want to emphasize that as competitors, the only thing we should take care about is target metrics value. Speed, complexity and memory consumption, all this doesn't matter as long as you're able to calculate it and re-produce your own results. Let's highlight key points. Real world machine learning pipelines are very complicated and consist of many stages. Competitions, add weight to a lot of things about modeling and data analysis, but in general they don't address the questions of formalization, deployment and testing. Now, I want to say a few words about philosophy on competitions, in order to form a right impression. We'll cover these ideas in more details later in the course along with examples. The first thing I want to show you is that, machine learning competitions are not only about algorithms. An algorithm is just a tool. Anybody can easily use it. You need something more to win. Insights about data are usually much more useful than a returned ensemble. Some competitions could be solved analytically, without any sophisticated machine learning techniques. In this course, we will show you the importance of understanding your data, tools to use and features you tried to exploit in order to produce the best solution. The next thing I want to say, don't limit yourself. Keep in mind that the only thing you should care about is target metric. It's totally fine to use heuristics or manual data analysis in order to construct golden feature and improve your model. Besides, don't be afraid of using complex solutions, advance feature engineering or doing the huge gritty calculation overnights. Use all the ways you can find in order to improve your model. After passing this course, you will able to get the maximum gain from your data. And now the important aspect is creativity. You need to know traditional approaches of solid machine learning problems but, you shouldn't be bounded by them. It's okay to modify or hack existing algorithm for your particular task. Don't be afraid to read source codes and change them, especially for deploying stuff. In our course, we'll show you examples of how a little bit of creativity can lead to constructing golden features or entire approaches for solving problems. In the end, I want to say enjoy competitions. Don't be obsessed with getting money. Experience and fun you get are much more valuables than the price. Also, networking is another great advantage of participating in data science competition. I hope you find this course interesting.